import sb.parse_utils  # for sb.parse_utils.init(...)
import io
import tarfile    # if the output parameter is used
import json           # to parse the Result JSON
import re             # to match the Result line
from typing import List, Dict, Any, Set, Tuple

VERSION: str = "2025/04/29"

FINDINGS: set[str] = {
    "reentrancy-eth",
    "controlled-array-length",
    "suicidal",
    "controlled-delegatecall",
    "arbitrary-send",
    "tod",
    "uninitialized-state",
    "parity-multisig-bug",
    "incorrect-equality",
    "integer-overflow",
    "unchecked-lowlevel",
    "tx-origin",
    "locked-ether",
    "unchecked-send",
    "boolean-cst",
    "erc721-interface",
    "erc20-interface",
    "costly-loop",
    "timestamp",
    "block-other-parameters",
    "calls-loop",
    "low-level-calls",
    "erc20-indexed",
    "erc20-throw",
    "hardcoded",
    "array-instead-bytes",
    "unused-state",
    "costly-operations-loop",
    "send-transfer",
    "boolean-equal",
    "external-function"
}
"""set of strings: all possible findings, of which 'findings' below will be a subset"""


def parse(exit_code, log, output):
    """
    Analyse the result of the tool run.

    :param exit_code: int|None, exit code of Docker run (None=timeout)
    :param log: list[str], stdout/stderr of Docker run
    :param output: bytes, tar archive of files generated by the tool (if specified in config.yaml)

    :return: tuple[findings: list[dict], infos: set[str], errors: set[str], fails: set[str]]
      findings identifies the major observations of the tool,
      infos contains any messages generated by the tool that might be of interest,
      errors lists the error messages deliberately generated by the tool,
      fails lists exceptions and other events not expected by the tool,
      analysis contains any analysis results worth reporting
    """

    findings, infos = [], set()
    errors, fails = sb.parse_utils.errors_fails(exit_code, log)

    try:
        for line in log:
            cleaned_line = line.strip()
            if cleaned_line.endswith("!") and not cleaned_line.endswith("sequence!") and not cleaned_line.endswith("precessing!"):
                # The original authors of VulHunter do not implement error handling, but seem to like exclamation marks for important messages
                infos.add(line.strip())

        if output is None:
            if len(errors) == 0:
                errors.add("No output generated by the tool")
            return findings, infos, errors, fails

        with io.BytesIO(output) as o, tarfile.open(fileobj=o) as tar:
            # access specific file
            output = tar.extractfile("output.json").read()

            data = json.loads(output)

            infos.add(f"OK")

            # Process each vulnerability type entry
            for entry in data:
                title = entry.get("title", "unknown")
                severity = entry.get("severity", "unknown")
                description = entry.get("description", "")
                description += f". Confidence: {entry.get("confidence", "unknown")}"

                # Process positions array
                if "positions" in entry:
                    for position_entry in entry["positions"]:
                        # Each position entry is [position_index, array_of_results]
                        if len(position_entry) >= 2:
                            results_array = position_entry[1]

                            # Check each result in the array
                            for result in results_array:
                                # We're looking for entries where the second value is true
                                # and result[1] is True # This boolean value seems to indicate if the result can be mapped to a certain position in source code or not, we do not interpret it as a sign to ignore it in case False
                                if len(result) >= 4:
                                    importance = result[0]
                                    location_info = result[2]
                                    position_value = result[3]

                                    loc_desc = "contract" if not isinstance(
                                        location_info, str) else location_info

                                    message = f"Importance: {importance}, Position: {position_value}, Location: {loc_desc}"

                                    finding = {
                                        "name": title,
                                        "severity": severity,
                                        "message": message
                                    }

                                    # Create finding if location info contains begin/end
                                    if isinstance(location_info, dict) and "begin" in location_info and "end" in location_info:
                                        line_num = location_info["begin"]["line"]
                                        column_num = location_info["begin"]["column"]
                                        line_end = location_info["end"]["line"]
                                        column_end = location_info["end"]["column"]

                                        finding["line"] = line_num
                                        finding["column"] = column_num
                                        finding["line_end"] = line_end
                                        finding["column_end"] = column_end

                                    findings.append(finding)
                # If no positions are found, still report on the finding
                if len(findings) == 0:
                    findings.append({
                        "name": title,
                        "severity": severity,
                        "message": description
                    })

    except json.JSONDecodeError as e:
        fails.add(f"JSON parsing error: {e}")
    except Exception as e:
        fails.add(f"Unexpected error processing results: {str(e)}")

    return findings, infos, errors, fails


"""
findings is a list of issues. Each issue is a dict with the following fields.
name: str
    mandatory. Identifies the type of issue
filename: str
    optional. Path of file processed. As this is the path within
    the docker image, it will be replaced by the external filename,
    after parsing.
contract: str
    optional. Name of contract within the file (for source code)
function: str
    optional. Name/header/signature of function containing the issue
line: int
    optional. Line number of issue in source code, starting with 1
column: int
    optional. Column of issue in source code, starting with 1
line_end: int
    optional. Last line of the source code, where issue occurs.
column_end: int
    optional. Last column of the source code, where issue occurs.
address: int
    optional. Address of instruction in the bytecode, where issue occurs, starting with 0
address_end: int
    optional. Address of last instruction in the bytecode, where issue occurs, starting with 0
exploit: Any
    optional. Information on a potential exploit, e.g. a list of transactions
level: str
    optional. type of issue, e.g. recommendation, warning, error
severity: str
    optional. Severity of issue, e.g. low, medium, high
message: str
    optional. Description of the issue

If missing, the fields severity, classification, method, descr_short,
descr_long will be taken from the file findings.yaml in the tools
directory (if it exists), with "name" serving as the key.
"""
